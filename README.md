
Title And Authors ;

Data Loss Detector: Automatically Revealing Data Loss Bugs in Android Apps

“Conference ISSTA-2020 Program”

Authors Name:-

(1) Oliviero Riganelli

(2) Simone Paolo Mottadelli

(3) Claudio Rota

(4) Daniela Micucci

(5) Leonardo Mariani

Introduction And Motivation:-

In the last Paper, mobile apps have increasingly gained importance and popularity.. Recent studies revealed that people spend more than 3h per day on their smartphones on average and that 90% of this time is typically devoted to the use of mobile apps . Among the available ecosystems for the distribution of mobile apps, the Android ecosystem is the largest and most used one: its market share is almost 75% and its official store, the Google Play Store, includes almost 3.0 millions of apps. Android apps consist of components, such as activities, fragments, and services, whose behavior must comply with well-defined lifecycles. Interestingly, some of these callbacks might be particularly tricky to implement. This is the case of the callbacks produced by stop start events, which are system events that may force the destruction and then the (re-)instantiation of a running activity. When a stop-start event occurs, the difficult task for the app is to handle the destruction of the current activity in a way that is later possible to resume the execution at the same point it was interrupted. This is done by saving the values of all the relevant state variables before the activity is destroyed, and retrieving these values when the execution is resumed. When a stop-start event is not properly handled, the Android app is said to be affected by a data loss fault, that is, a fault that causes one or more state variables to lose their values. Data loss faults may affect the correctness of the apps in many different ways. In the best cases, they force the users to enter again inputs that had already been entered, deteriorating the quality of the user experience. In the worst cases, they generate activities with an inconsistent state, which causes the apps to produce wrong outputs or even crashes. It reports the largest empirical evaluation about data loss detection available so far, considering hundreds of data loss faults.

Research And Methodology:- 

Research Qno1= How effective is DLD with data loss problems?
Research Qno2= Is DLD more effective than state-of-the-art techniques? 
Research Qno3= What is the tradeoff between the snapshot- and property-based oracles?
Research Qno4= - Are data loss faults relevant to developers?
Data loss problems do not always cause crashes. On the contrary, apps can present a range of misbehaviors. DLD uses oracles based on the fact that the operations that exercise the data loss faults are expected to be neutral, thus leaving the status of the app unchanged. DLD defines two oracle strategies, which can be used either independently or jointly: the snapshot-based oracle and the property based oracle. The snapshot-based oracle takes a screenshot of the app before and after a data loss might have occurred and compares the images to detect failures. State Information: DLD first takes a screenshot of the device. The recorded image is then converted into a grayscale image, which is faster to compare than a colorful image. Finally, DLD crops the header and the footer of the image because it contains information that changes over time regardless of data loss, such as the current time and the battery level. The resulting image is the retrieved representation of the current state.

Results:-

Ans RQ no1 = To answer this research question, we manually analyzed every report produced by DLD to distinguish the actual data loss problems from the irrelevant spurious violations. In particular, we classified a reported data loss as spurious if one of the two following conditions holds: (1) the state of the app after the double screen rotation is taken too early, while the activity is still recreating, making the oracle to fail its check or (2) the difference reported by the oracle cannot be considered a data loss (e.g., because the tested app shows the current time which obviously changes after the screen has been rotated twice). The results that DLD obtained for all the app releases considered in the study. Since every row represents the outcome of three runs, when applicable, we report both average values and total values. Column Crashes reports the total number of activities that crashed due to data loss faults.
Ans RQ no2 = This research question compares DLD to both Alaric and Quantum. Alaric represents the case of an alternative automated approach to reveal data loss faults, while Quantum represents the case of an approach that can benefit from a manually generated model to generate data loss-revealing test cases. The comparison to Alaric studies the effectiveness of the test generation strategy defined in DLD, to Alaric, which uses a random (non-biased) exploration and a concrete states representation. DLD significantly outperformed Alaric in terms of data loss discovery capability. In fact, Alaric revealed 71 activities affected by data loss faults, while DLD revealed 189 faulty activities, releasing a 2.7X factor of improvement. Alaric found 19 data loss faults of the benchmark, 8 online data loss faults, and 50 new data loss faults. Since we do not know the manual effort that was necessary to manually define the models used by Quantum, it is hard to setup a fair comparison among the two approaches. However, the obtained results can still offer useful insights about the relative effectiveness of the two approaches. ALARic does not reach 52% of the faulty activities revealed by DLD only, that is, approximatively half of the additional data loss faults revealed by DLD are due to a better exploration strategy. Although the snapshot-based oracle produces more spurious violations than the property-based oracle, these violations seldom cause correct activities to be reported to the tester (1 activity every 4 apps), thus it is relatively detrimental to use it in the testing process. On the contrary, including it in the analysis increases the number of revealed data loss faults by 9.2%, which is a non-trivial increase of the failure discovery ability of DLD.
Ans RQ no3 = This research question investigates the complementarity between the snapshot-based and the property-based oracles. The qualitative differences between these two types of oracles, and reported examples of data loss faults that could be detected by one type of oracle only. The percentage of data loss faults detected and the number of spurious oracle violations produced by one-strategy only, either snapshot-based or property-based, or both of them. In the case of the spurious violations we have an additional category that is the violations caused by slow activity recreation after screen rotation, as anticipated in the Section discussing RQ1. In terms of absolute failure discovery ability, both oracles have been effective, with the property-based and snapshot-based oracles revealing 90.9% and 82.3% of the failures, respectively. This percentage can be reduced or eliminated by carefully tuning the timing of the oracles. The largest proportion of the spurious violations (73.6%) are produced by both the strategies. Although the snapshot-based oracle produces more spurious violations than the property-based oracle, these violations seldom cause correct activities to be reported to the tester (1 activity every 4 apps), thus it is relatively detrimental to use it in the testing process. On the contrary, including it in the analysis increases the number of revealed data loss faults by 9.2%, which is a non-trivial increase of the failure discovery ability of DLD.
Ans RQ no4 = We investigated if data loss faults are relevant to app developers. To this end, for each app in the benchmark, we identified and downloaded the latest version of the same app. We executed again DLD for 9 hours (three 3-hours runs) on each app and revealed 195 data loss faults that still affect these apps nowadays. We finally submitted a bug report online for each revealed data loss. Developers confirmed the bugs for 88 reports (90% of the reports with a feedback). Only in 10 cases developers rejected the report advocating that the fault was a framework fault, claiming the fault was not reproducible, or giving no explanation. In 33 of 88 cases developers claimed that the cost of fixing these bugs might be too high compared to their impact on the app. This decision of course depends on the specific consequence of the data loss and the complexity of the activity that is affected by the fault.

Conclusions :-

Android apps must be designed to deal with stop-start events, which are external events that may interrupt the execution of the running activity. To avoid losing useful data during this process, apps must explicitly implement the logic necessary to save the data, when the activity is destroyed, and restore the saved data, when the activity is recreated. This paper presents Data Loss Detector (DLD), an automatic test case generation technique designed to reveal data loss faults. DLD exploits an exploration strategy biased towards the discovery of new app states, data-loss-revealing actions, and two dedicated oracle-based strategies to automatically reveal data loss problems. Overall, DLD revealed 298 activities affected by data loss faults, which is a clear indicator of the effectiveness of the approach and pervasiveness of the problem.

